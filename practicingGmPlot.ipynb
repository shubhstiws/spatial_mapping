{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gmplot import gmplot\n",
    "%matplotlib inline\n",
    "\n",
    "# Place map\n",
    "gmap = gmplot.GoogleMapPlotter(37.766956, -122.438481, 13)\n",
    "\n",
    "# Polygon\n",
    "golden_gate_park_lats, golden_gate_park_lons = zip(*[\n",
    "    (37.771269, -122.511015),\n",
    "    (37.773495, -122.464830),\n",
    "    (37.774797, -122.454538),\n",
    "    (37.771988, -122.454018),\n",
    "    (37.773646, -122.440979),\n",
    "    (37.772742, -122.440797),\n",
    "    (37.771096, -122.453889),\n",
    "    (37.768669, -122.453518),\n",
    "    (37.766227, -122.460213),\n",
    "    (37.764028, -122.510347),\n",
    "    (37.771269, -122.511015)\n",
    "    ])\n",
    "gmap.plot(golden_gate_park_lats, golden_gate_park_lons, 'cornflowerblue', edge_width=10)\n",
    "\n",
    "# Scatter points\n",
    "top_attraction_lats, top_attraction_lons = zip(*[\n",
    "    (37.769901, -122.498331),\n",
    "    (37.768645, -122.475328),\n",
    "    (37.771478, -122.468677),\n",
    "    (37.769867, -122.466102),\n",
    "    (37.767187, -122.467496),\n",
    "    (37.770104, -122.470436)\n",
    "    ])\n",
    "gmap.scatter(top_attraction_lats, top_attraction_lons, '#3B0B39', size=40, marker=False)\n",
    "\n",
    "# Marker\n",
    "hidden_gem_lat, hidden_gem_lon = 37.770776, -122.461689\n",
    "gmap.marker(hidden_gem_lat, hidden_gem_lon, 'cornflowerblue')\n",
    "\n",
    "# Draw\n",
    "gmap.draw(\"my_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query(outFormat = 'text', starttime = '2016-02-01', endtime = '2016-03-01', minmagnitude = 5.0):\n",
    "    '''\n",
    "    Funciton to build the url for query the data. Details can be found at USGS api documentation:\n",
    "    http://earthquake.usgs.gov/fdsnws/event/1/\n",
    "    \n",
    "    Note: you can add more parameters, but I just need time range and minmum magnitude to start with. \n",
    "    '''\n",
    "    base = 'http://earthquake.usgs.gov/fdsnws/event/1/query?'\n",
    "    url = base + 'format=' + outFormat + '&starttime=' + starttime + '&endtime=' + endtime + '&minmagnitude=' + str(minmagnitude)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_result(inputText):\n",
    "    '''\n",
    "    Function to parse the requested earthquake events data from USGS, and save it into numpy array\n",
    "    '''\n",
    "    event_id = []\n",
    "    origin_time = []\n",
    "    evla = []\n",
    "    evlo = []\n",
    "    evdp = []\n",
    "    mag = []\n",
    "    mag_type = []\n",
    "    EventLocationName  = []\n",
    "    for i, item in enumerate(inputText.split('\\n')[0:-1]):\n",
    "        if i < 1:\n",
    "            # skip the header\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            splited = item.split('|')\n",
    "            event_id.append(splited[0])  \n",
    "            origin_time.append(splited[1])\n",
    "            evla.append(splited[2])\n",
    "            evlo.append(splited[3])\n",
    "            evdp.append(splited[4])\n",
    "            mag.append(splited[10])\n",
    "            mag_type.append(splited[9])\n",
    "            EventLocationName.append(splited[-1])\n",
    "        except:\n",
    "            # just in case there are some wrong data in the catlog\n",
    "            print (item)\n",
    "            print ('Skip wrong data or there is something wrong') \n",
    "        \n",
    "    return np.c_[event_id, origin_time, evla, evlo, mag, mag_type, EventLocationName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://earthquake.usgs.gov/fdsnws/event/1/query?format=text&starttime=2010-01-01&endtime=2016-01-01&minmagnitude=5.0\n"
     ]
    }
   ],
   "source": [
    "url = build_query(outFormat = 'text', starttime = '2010-01-01', endtime = '2016-01-01', minmagnitude = 5.0)\n",
    "print (url)\n",
    "\n",
    "# get the earthquake data from USGS and parse them into a numpy array\n",
    "with urllib.request.urlopen(url) as url:\n",
    "    s = url.read()\n",
    "r = s\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "events_mat = parse_result(soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = [float(item[2]) for item in events_mat]\n",
    "lons = [float(item[3]) for item in events_mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the center of the map, and how much we want the map zoomed in\n",
    "gmap = gmplot.GoogleMapPlotter(0, 0, 2)\n",
    "# plot heatmap\n",
    "gmap.heatmap(lats, lons)\n",
    "# save it to html\n",
    "gmap.draw(\"Earthquake_heatmap.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minneapolis 311 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./Data/Public_311_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmap = gmplot.GoogleMapPlotter.from_geocode(\"Minneapolis\")\n",
    "gmap.heatmap(df['Y'], df['X'])\n",
    "gmap.draw(\"./Output/311_2017.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minneapolis Snow Emergency Jane Tows 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "url = 'https://services.arcgis.com/afSMGVsC7QlRK1kZ/arcgis/rest/services/Snow_Emergency_Jane_Tows_2017/\\\n",
    "FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json'\n",
    "with urllib.request.urlopen(url) as url:\n",
    "    s = url.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas.io.json import json_normalize\n",
    "df = pd.io.json.json_normalize(json.loads(s)['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmap = gmplot.GoogleMapPlotter.from_geocode(\"Minneapolis\",12)\n",
    "gmap.heatmap(df['geometry.y'], df['geometry.x'])\n",
    "gmap.draw(\"./Output/snow_plow_2017.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minneapolis Police Incidents 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://services.arcgis.com/afSMGVsC7QlRK1kZ/arcgis/\\\n",
    "rest/services/PoliceOffense2016/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json'\n",
    "with urllib.request.urlopen(url) as url:\n",
    "    s = url.read()\n",
    "df = pd.io.json.json_normalize(json.loads(s)['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmap = gmplot.GoogleMapPlotter.from_geocode(\"Minneapolis\",12)\n",
    "gmap.heatmap(df['geometry.y'], df['geometry.x'])\n",
    "gmap.draw(\"./Output/police_incidents_2016.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chicago Crimes since 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Crimes_-_2001_to_present.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf15]",
   "language": "python",
   "name": "conda-env-tf15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
